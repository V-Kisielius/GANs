{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8953dcbc",
   "metadata": {},
   "source": [
    "# VAE + GAN\n",
    "https://arxiv.org/pdf/1512.09300.pdf\n",
    "\n",
    "Попробуем улучшить генерацию за счет применения GAN\n",
    "\n",
    "$X$ - входной объект из $X$\n",
    "\n",
    "$Z_p$ - сэмплированный $Z$ из $P(Z)$\n",
    "\n",
    "$X_p$ - объект, сгенерированный декодером из $Z_p$\n",
    "\n",
    "$\\tilde{X}$ - объект, восстановленный из $X$\n",
    "\n",
    "$L_{prior} = D_{KL}(Q(Z|X) || P(Z))$ - лосс, заставляющий энкодер переводить $P(X)$ в нужное нам $P(Z)$\n",
    "\n",
    "$L_{llike}^{Dis_l} = L_d(d_l(X), d_l(\\tilde{X}))$ - лосс, между активациями l-ого слоя дискриминатора $D$ на реальном $X$ и восстановленном $\\tilde{X}$\n",
    "\n",
    "$L_{GAN} = log(D(X)) + log(1 - D(f_d(Z))) + log(1 - D(f_d(Q(X))))$ - кросс-энтропия между реальным распределением лейблов настоящих/сгенерированных объектов, и распределнием вероятности, предсказываемым дискриминатором.\n",
    "\n",
    "Схема, предлагаемая авторами:\n",
    "\n",
    "$\\theta_{Enc} = \\theta_{Enc} - \\Delta_{\\theta_{Enc}}(L_{prior} + L_{llike}^{Dis_l})$\n",
    "\n",
    "$\\theta_{Dec} = \\theta_{Dec} - \\Delta_{\\theta_{Dec}}(\\gamma L_{llike}^{Dis_l} - L_{GAN})$\n",
    "\n",
    "$\\theta_{Dis} = \\theta_{Dis} - \\Delta_{\\theta_{Dis}}(L_{GAN})$\n",
    "m\n",
    "Каждую из трех моделей нужно учить по очереди."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57208e2a",
   "metadata": {},
   "source": [
    "# Подключение необходимых модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed09f3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from VAEGANcfg import device, batch_size, epochs, lr, alpha, gamma\n",
    "from VAEGAN import VAE_GAN, Discriminator\n",
    "\n",
    "print(f'Selected device is {device}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fba01888",
   "metadata": {},
   "source": [
    "# Загрузка датасета MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef41c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([ transforms.Resize(64),transforms.CenterCrop(64),transforms.ToTensor(),transforms.Normalize((0.5),(0.5))])\n",
    "dataset=MNIST(root=\".\", train=True,transform=transform, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c38131f6",
   "metadata": {},
   "source": [
    "## Определение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df302cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=VAE_GAN().to(device)\n",
    "discrim=Discriminator().to(device)\n",
    "real_batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20192c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss().to(device)\n",
    "optim_E=torch.optim.RMSprop(gen.encoder.parameters(), lr=lr)\n",
    "optim_D=torch.optim.RMSprop(gen.decoder.parameters(), lr=lr)\n",
    "optim_Dis=torch.optim.RMSprop(discrim.parameters(), lr=lr*alpha)\n",
    "z_fixed=Variable(torch.randn((64,128))).to(device)\n",
    "x_fixed=Variable(real_batch[0]).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "752272d0",
   "metadata": {},
   "source": [
    "## Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f293987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/938]\tLoss_gan: 2.8758\tLoss_prior: 0.1302\tRec_loss: 0.7129\tdis_real_loss: 1.0043\tdis_fake_loss: 0.8517\tdis_prior_loss: 1.0198\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15080/1990474052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mones_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mzeros_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mzeros_label1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    prior_loss_list,gan_loss_list,recon_loss_list=[],[],[]\n",
    "    dis_real_list,dis_fake_list,dis_prior_list=[],[],[]\n",
    "    for i, (data,_) in enumerate(data_loader, 0):\n",
    "        bs=data.size()[0]\n",
    "\n",
    "        ones_label=Variable(torch.ones(bs,1)).to(device)\n",
    "        zeros_label=Variable(torch.zeros(bs,1)).to(device)\n",
    "        zeros_label1=Variable(torch.zeros(64,1)).to(device)\n",
    "        datav = Variable(data).to(device)\n",
    "        mean, logvar, rec_enc = gen(datav)\n",
    "        z_p = Variable(torch.randn(64,128)).to(device)\n",
    "        x_p_tilda = gen.decoder(z_p)\n",
    "\n",
    "        output = discrim(datav)[0]\n",
    "        errD_real = criterion(output, ones_label)\n",
    "        dis_real_list.append(errD_real.item())\n",
    "        output = discrim(rec_enc)[0]\n",
    "        errD_rec_enc = criterion(output, zeros_label)\n",
    "        dis_fake_list.append(errD_rec_enc.item())\n",
    "        output = discrim(x_p_tilda)[0]\n",
    "        errD_rec_noise = criterion(output, zeros_label1)\n",
    "        dis_prior_list.append(errD_rec_noise.item())\n",
    "        gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
    "        gan_loss_list.append(gan_loss.item())\n",
    "        optim_Dis.zero_grad()\n",
    "        gan_loss.backward(retain_graph=True)\n",
    "        optim_Dis.step()\n",
    "\n",
    "\n",
    "        output = discrim(datav)[0]\n",
    "        errD_real = criterion(output, ones_label)\n",
    "        output = discrim(rec_enc)[0]\n",
    "        errD_rec_enc = criterion(output, zeros_label)\n",
    "        output = discrim(x_p_tilda)[0]\n",
    "        errD_rec_noise = criterion(output, zeros_label1)\n",
    "        gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
    "\n",
    "\n",
    "        x_l_tilda = discrim(rec_enc)[1]\n",
    "        x_l = discrim(datav)[1]\n",
    "        rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
    "        err_dec = gamma * rec_loss - gan_loss \n",
    "        recon_loss_list.append(rec_loss.item())\n",
    "        optim_D.zero_grad()\n",
    "        err_dec.backward(retain_graph=True)\n",
    "        optim_D.step()\n",
    "\n",
    "        mean, logvar, rec_enc = gen(datav)\n",
    "        x_l_tilda = discrim(rec_enc)[1]\n",
    "        x_l = discrim(datav)[1]\n",
    "        rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
    "        prior_loss = 1 + logvar - mean.pow(2) - logvar.exp()\n",
    "        prior_loss = (-0.5 * torch.sum(prior_loss))/torch.numel(mean.data)\n",
    "        prior_loss_list.append(prior_loss.item())\n",
    "        err_enc = prior_loss + 5*rec_loss\n",
    "\n",
    "        optim_E.zero_grad()\n",
    "        err_enc.backward(retain_graph=True)\n",
    "        optim_E.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_gan: %.4f\\tLoss_prior: %.4f\\tRec_loss: %.4f\\tdis_real_loss: %0.4f\\tdis_fake_loss: %.4f\\tdis_prior_loss: %.4f'\n",
    "                      % (epoch,epochs, i, len(data_loader),\n",
    "                         gan_loss.item(), prior_loss.item(),rec_loss.item(),errD_real.item(),errD_rec_enc.item(),errD_rec_noise.item()))\n",
    "\n",
    "\n",
    "    b=gen(x_fixed)[2]\n",
    "    b=b.detach()\n",
    "    c=gen.decoder(z_fixed)\n",
    "    c=c.detach()\n",
    "    #show_and_save('MNISTrec_noise_epoch_%d.png' % epoch ,make_grid((c*0.5+0.5).cpu(),8))\n",
    "    #show_and_save('MNISTrec_epoch_%d.png' % epoch ,make_grid((b*0.5+0.5).cpu(),8))\n",
    "\n",
    "#plot_loss(prior_loss_list)\n",
    "#plot_loss(recon_loss_list)\n",
    "#plot_loss(gan_loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
